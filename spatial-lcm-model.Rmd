---
title: "spatial-lcm-model"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Oct 16, 2019

### Multi-pollutant exposure profiles associated with term low birth weight in Los Angeles County
Basic Structure of Coker model:

* Two land use regression models to estimate individual-level exposures for PM_2.5, NO, and NO_2
  + exposure predictions based on traffic volumes, truck routes, road networks, land use data, satellite-derived vegetation greenness and soil brightness, truck route slope gradients, and air monitoring data

  + machine-learning deletion substitution method to assess 70 covariates to determine final LUR model
  
  + adjusted LUR exposure estimates temporally to derive seasonalized values

* Aggregated data at census-block group-level for individual estimates to use R PReMiuM package

* Bayesian profile regression

  + based on Dirichlet process mixture model methods
  + added the cited resource to Mendeley
  + utilized feature of PReMiuM package that allows you to leave out the outcome variable from profile regression model (I agree with this for what we are doing)
  + "hard clustering" = each census block group falls in a single cluster (agree for simplicity)
  + "best" cluster derived from Bayesian averaging process, rather than probabilistic allocation to several different clusters simultaneously (What does this mean? Look into the bayesian averaging process)

$logit(p_i) = \alpha _ V \eta' + \gamma_{k[i]}^{pollutant-cluster} + \gamma_{c[i]}^{contextual-cluster} + S_j + \epsilon_j$

* cluster random effects can be interpreted as measuring change in baseline log odds of TLBW for individual $i$ in cluster $k$, when all other covariates in the model are set to zero. 

* spatial and independent resitual error terms (pg. 4 of paper)
  + weights based on a zero-one neighborhood adjacency matrix


### Ideas for changes

* In PReMiuM package, can only allow a CAR (conditional autoregressive) term. 
  + experiment with other covariance structures? 
  + no, this is not relevant

* What would changing the neighborhood-adjacency matrix do? Different weights? Also weight those census blocks that are two-away from your census block, etc.
  + weighting based on distance (distance between center of census tract)

* another idea for a paper: simply comparing methods: 
  + bayesian profile regression vs. 
  + latent class model 

### Next Steps

* Familiarize with Dirichlet process mixture model methods (Neal, 2000)
* Explore PReMiuM package
* Load pollutant data into R
* load SES data into R
* explore ggmaps
* Reproduce a raw data map of a pollutant level (alex's code)
* Create a correlation matrix of all variables

### Question

* How did they categorize the exposure levels into low, moderate, and high levels? 
* Geocoding

### Specific meeting notes: 

* On the topic of re-weighting the neighborhood-adjacency matrix, perhpas one optio could be to weight based on "how much" the census tracts are touching. So for example, if they are touching just on a corner (one point), weight that less than if they are touching along a long distance (like they share a border for quite a ways). 

* Another option for re-weighting could be to use distances between census tracts. For example a spatial power structure. (SP(POW(c-list)) in SAS) 

* Noted that the latent class model does a probabilistic way. For example, this person belongs to this latent class "with .8 probability" and belongs to this other latent class "with .2 probability". Then these probabilities get carried forward in the computation process. However, in the bayesian profile classification method (Coker paper), they use "hard clustering" so they firmly decide which cluster you belong to during classification, and then no probabilities get carried forward. (You have a probability of 1 of being in a certain cluster, and that is brought forward to subsequent steps). 

* Terry notes that, intuitively, similarity of pollution over space is different than similarity of SES over space. How can we incorporate this into a model? 

* Note that Bayesian profile regression is just to get the fixed effects. Random effects are found in subsequent steps. 

* Terry was wondering: When you estimate fixed effects, you get standard errors. How does Coker model handle these? Do they get brought into the next modeling steps? Or are they just ignored (i.e. do they just plug in fixed effects)

### Oct 17, 2019

* In Besag, York, and Mollie (Bayesian Image Restoration with two applications in spatial statistics), they discuss the weights used in the zero-one adjacent-neighborhood matrix

#### Description of BYM Model

* Let $x_i$ denote the unknown log relative risk in zone $i$ $(i=1, \ldots, n)$ and $y_i$ the corresponding observed number of cases of (or deaths from) the disease during the study period. 

* Assume $y_i|x_i\sim Poi(c_ie^{x_i})$ are independent variables, where $c_i$ is the expected number of cases in zone $i$ assuming constant risk. 

* $x=t+u+v$
  + $t$ is standard term, associated with measured covariates that are known or suspected to be relevant to the disease (usually $t=A\theta$ with at least $A$ known)
  + $u$ and $v$ are surrogates for unknown or unobserved covariates
  + if $u_i$ were observed, they would display substantial spatial structure
  + $v_i$ are unstructured variables (Breslow (1984) wanted to include these since he noted strong empirical evidence of extra-Poisson variation under the basic model $x=A\theta$)
  + if $u$ dominates $v$, then the estimated risks will display spatial structure
  

### 10/18/19 Meeting Notes

* Updates: 
  + got the NATA data loaded in to my project.
  + set up a project file on github
  + reproduced the raw census tract pollutant maps from NATA data
  + added documentation for R-INLA, the package used to implement the Bayesian random effects model, into Mendeley 
  + Bayesian Image Analysis in Spatial Statistics (Besag, York, and Mollie) briefly mentions that the neighborhood adjacency matrix could reflect populations at risk or common boundary length
  + Tori's email

* Questions:
  + It is okay to have the NATA and SES data on Box/Docker? (Is this protected data?)
  + Is the A1C data protected? (Will it be de-identified? Will it be okay to keep it on Box/Docker?)
  + BYM: What is intuition behind weighting the neighborhood-adjacency matrix based on population? Weigh higher population higher than lower-pop?
  + What is the role of the neighborhood adjacency matrix? Just to take into account what's going on in the census tracts around you? 

* Plan of action
  + Bayesian profile regression (R PReMiuM) gets fixed effects. 
  + R-INLA (integrated nested Laplace approximations) implements the Bayesian multilevel random effects model:

$logit(p_i) = \alpha _ V \eta' + \gamma_{k[i]}^{pollutant-cluster} + \gamma_{c[i]}^{contextual-cluster} + S_j + \epsilon_j$

+ Need clarification: (pg 4 of Coker 2016) "Given the large number of records in the dataset, we "pre-clustered" exposure profiles as described in our clustering section and then used the R-INLA package to implement the Bayesian multilevel random effects model described above". 


### 10/19/19

* In R PReMiuM package, when using profregr, what are the fixed effects?
* Should the bayesian profile regression be done on the raw values of total concentration, and not the percentages (wrt NC)?
* how to interpret the output of the bayesian profile regression? Where are the clusters? 
* ask Alex if she has code to merge the datasets together (ACS and NATA)


### 10/29/19

* Stuck on R PReMiuM package = profRegr
  + I think we need to have an outcome already present in the dataset
  + Need to possibly specify fixed effects?
  + "input file not found" = is the function not finding the data frame?
  + nothing is going in my output folder. 
  
* Geocoding
  + Can use geocode function in ggmap package
  + need an API key from google cloud
  + 12 month, free trial available
  + trial ends at earliest of: 12 months after making a billing account, or when the allowed usage exceeds $300
  + (costs: $5.00 per 1000 if requesting 1-100,000)
  
  + What I've done so far:
  + I went to this website: https://cloud.google.com/maps-platform/#get-started
  + I initiated a project called SES-env1 (linked to my personal gmail account)
  + I created an API key for that project
  + Now I'm not sure how to actually use that API key to do the geocoding in R
  + There is a function called "register_google" within the ggmap package, and it requires a bunch of inputs and credentials. Not sure how to get credentials. 
  + Much of the confusion is coming from the fact that a lot of the instructions on the google page are aimed at people who are creating an app or a website where they want users to be able to look up maps of things. 
  
  + I tried the following code but it didn't work:
  
```{r}
# ggmap::register_google(key = "AIzaSyCDGuul7IjO4UfDYGp1naD0Y8eLydjOwAg")
```

I got the following error message:

Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]) : 
  there is no package called ‘jpeg’
  
 + So then I tried install.packages("jpeg"), and I got the following error:

In file included from read.c:1:
./rjcommon.h:11:10: fatal error: 'jpeglib.h' file not found
#include <jpeglib.h>
         ^~~~~~~~~~~
1 error generated.
make: *** [read.o] Error 1
ERROR: compilation failed for package ‘jpeg’
* removing ‘/Library/Frameworks/R.framework/Versions/3.5/Resources/library/jpeg’

  + So then I googled this error and am currently trying to troubleshoot it. 
  

### 10/30/19

* Janice knows someone who can probably help me with the geocoding in 30 seconds. She is emailing her today and will get back to me. 
* Bayesian class is during IBIEM so can't take it. 
* other options: BIOS 822 or BME 590
  